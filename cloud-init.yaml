#cloud-config
write_files:
  - path: /root/conf/enabled_plugins
    content: |
        [prometheus_rabbitmq_exporter,rabbitmq_management].
  - path: /root/conf/rabbitmq.config
    content: |
        [ { rabbit, [
          { loopback_users, [ ] } ] }
         ].
  - path: /etc/sysconfig/docker
    content: |
      # The max number of open files for the daemon itself, and all
      # running containers.  The default value of 1048576 mirrors the value
      # used by the systemd service unit.
      DAEMON_MAXFILES=1048576

      # Additional startup options for the Docker daemon, for example:
      # OPTIONS="--ip-forward=true --iptables=true"
      # By default we limit the number of open files per container
      OPTIONS="--default-ulimit nofile=1000000:1048576"

      # How many seconds the sysvinit script waits for the pidfile to appear
      # when starting the daemon.
      DAEMON_PIDFILE_TIMEOUT=10
  - path: /etc/systemd/system/datadog-agent.service
    content: |
      [Unit]
      Description=Datadog Agent
      After=docker.service
      Requires=docker.service

      [Service]
      Restart=always
      ExecStartPre=-/usr/bin/docker stop dd-agent
      ExecStartPre=-/usr/bin/docker rm -f dd-agent
      ExecStart=/bin/bash /root/run_datadog_agent.sh
      ExecStop=/usr/bin/docker stop dd-agent
  - path: /opt/aws/amazon-cloudwatch-agent/bin/config.json
    content: |
      {
              "agent": {
                      "metrics_collection_interval": 30,
                      "run_as_user": "cwagent"
              },
              "logs": {
                      "logs_collected": {
                              "files": {
                                      "collect_list": [
                                              {
                                                      "file_path": "/var/log/cloud-init.log",
                                                      "log_group_name": "cloud-init.log",
                                                      "log_stream_name": "{instance_id}/cloud-init.log"
                                              },
                                              {
                                                      "file_path": "cloud-init-output.log",
                                                      "log_group_name": "cloud-init-output.log",
                                                      "log_stream_name": "{instance_id}/cloud-init-output.log"
                                              }
                                      ]
                              }
                      }
              },
              "metrics": {
                      "append_dimensions": {
                              "AutoScalingGroupName": "$${aws:AutoScalingGroupName}",
                              "ImageId": "$${aws:ImageId}",
                              "InstanceId": "$${aws:InstanceId}",
                              "InstanceType": "$${aws:InstanceType}"
                      },
                      "metrics_collected": {
                              "cpu": {
                                      "measurement": [
                                              "cpu_usage_idle",
                                              "cpu_usage_iowait",
                                              "cpu_usage_user",
                                              "cpu_usage_system"
                                      ],
                                      "metrics_collection_interval": 30,
                                      "totalcpu": false
                              },
                              "disk": {
                                      "measurement": [
                                              "used_percent",
                                              "inodes_free"
                                      ],
                                      "metrics_collection_interval": 30,
                                      "resources": [
                                              "*"
                                      ]
                              },
                              "diskio": {
                                      "measurement": [
                                              "io_time",
                                              "write_bytes",
                                              "read_bytes",
                                              "writes",
                                              "reads"
                                      ],
                                      "metrics_collection_interval": 30,
                                      "resources": [
                                              "*"
                                      ]
                              },
                              "mem": {
                                      "measurement": [
                                              "mem_used_percent"
                                      ],
                                      "metrics_collection_interval": 30
                              },
                              "netstat": {
                                      "measurement": [
                                              "tcp_established",
                                              "tcp_time_wait"
                                      ],
                                      "metrics_collection_interval": 30
                              },
                              "swap": {
                                      "measurement": [
                                              "swap_used_percent"
                                      ],
                                      "metrics_collection_interval": 30
                              }
                      }
              }
      }

  - path: /root/forget_hosts.sh
    content: |
        #!/usr/bin/env bash
        NODE=$1
        docker exec rabbitmq rabbitmqctl forget_cluster_node $1

  - path: /root/find_hosts.sh
    content: |
        #!/usr/bin/env bash

        export AWS_DEFAULT_REGION='${region}'

        DNSES=$(aws ec2 describe-instances --filters "Name=tag:aws:autoscaling:groupName,Values=${asg_name}" "Name=instance-state-name,Values=running" | jq ".Reservations[].Instances[].PrivateDnsName" | xargs)

        for dns in $DNSES; do
          # pulling out just the first part of the name, eg: ip-10-2-1-82.ec2.internal -> ip-10-2-1-82
          dns_subdomain=($${dns//./ })
          if  [ "$dns" != "$HOSTNAME" ] && [  "$dns_subdomain" != "$HOSTNAME" ] ; then
            echo $dns_subdomain
          fi
        done

  - path: /root/bin/join_cluster.sh
    content: |
        #!/usr/bin/env sh

        HOSTNAMES=( $@ )

        for run in {1..3}; do
          sleep $[ ( $RANDOM % 10 )  + 1 ]s
          echo "stopping rabbit to try and join other nodes"
          rabbitmqctl stop_app

          NEW_HOSTNAMES=()
          for peerhostname in $HOSTNAMES; do
            echo "trying to join $${peerhostname}"
            rabbitmqctl join_cluster rabbit@$peerhostname
            st=$?
            if [ $st -ne 0 ] && [ $st -ne 130 ]; then  # 130 is "already joined"
              NEW_HOSTNAMES+=( $peerhostname )
            fi
          done

          HOSTNAMES=( $${NEW_HOSTNAMES[@]} )
          rabbitmqctl start_app
          echo "startting rabbit after trying to join other nodes"

          if [ $${#HOSTNAMES[@]} -eq 0 ]; then
            exit 0
          fi
        done
  - path: /root/configure.sh
    content: |
        #!/usr/bin/env bash
        docker exec rabbitmq rabbitmqctl add_user admin ${admin_password}
        docker exec rabbitmq rabbitmqctl set_user_tags admin administrator
        docker exec rabbitmq rabbitmqctl add_user rabbit ${rabbit_password}
        docker exec rabbitmq rabbitmqctl add_vhost /
        docker exec rabbitmq rabbitmqctl set_policy -p / ha-three "^" '{"ha-mode":"exactly", "ha-params":${sync_node_count}, "ha-sync-mode":"automatic", "message-ttl":${message_timeout}}'
        docker exec rabbitmq rabbitmqctl set_permissions -p / admin ".*" ".*" ".*"
        docker exec rabbitmq rabbitmqctl set_permissions -p / rabbit ".*" ".*" ".*"
        docker exec rabbitmq rabbitmqctl delete_user guest
  - path: /root/datadog-agent/conf.d/rabbitmq.d/conf.yaml
    content: |
        ad_identifiers:
          - rabbitmq-eng

        init_config:

        instances:
          - rabbitmq_api_url: "http://%%env_IP%%:15672/api/"
            username: "datadog"
            password: "%%env_DD_RMQ_PASS%%"
  - path: /root/datadog-agent/datadog.yaml
    content: |
        ####### Defaults
        ## Provides autodetected defaults, for vanilla Docker environments,
        ## please see datadog.yaml.example for all supported options

        # Autodiscovery settings for vanilla Docker
        listeners:
          - name: docker
        config_providers:
          - name: docker
            polling: true
            poll_interval: 1s

        apm_config:
          apm_non_local_traffic: true

        # Use java container support
        jmx_use_container_support: true
        #######

        site: datadoghq.com

        tags:
          - application:${app_name}

        env: ${dd_env}

        apm_config:
          enabled: false

        # This setting value is a string
        # See https://github.com/DataDog/datadog-agent/blob/main/pkg/config/config_template.yaml
        process_config:
          enabled: "true"

        health_port: 5555

        logs_enabled: true

        logs_config:
          container_collect_all: true
  - path: /root/configure_datadog_user.sh
    content: |
        #!/usr/bin/env bash
        export DD_RMQ_PASS=$(aws ssm get-parameter --name ${dd_password} --with-decryption --region ${region} | jq -r '.Parameter.Value')
        docker exec rabbitmq rabbitmqctl add_user datadog $DD_RMQ_PASS
        docker exec rabbitmq rabbitmqctl set_user_tags datadog monitoring
        docker exec rabbitmq rabbitmqctl set_permissions -p / datadog "^aliveness-test$" "^amq\.default$" ".*"
  - path: /root/run_datadog_agent.sh
    content: |
        #!/usr/bin/env bash
        export DD_API_KEY=$(aws ssm get-parameter --name ${dd_api_key} --with-decryption --region ${region} | jq -r '.Parameter.Value')
        export DD_RMQ_PASS=$(aws ssm get-parameter --name ${dd_password} --with-decryption --region ${region} | jq -r '.Parameter.Value')
        export IP=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
        docker run --name dd-agent \
        -v /var/run/docker.sock:/var/run/docker.sock:ro \
        -v /proc/:/host/proc/:ro \
        -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro \
        -v /var/lib/docker/containers:/var/lib/docker/containers:ro \
        -v /opt/datadog-agent/run:/opt/datadog-agent/run:rw \
        -v /root/datadog-agent/datadog.yaml:/etc/datadog-agent/datadog.yaml:ro \
        -v /root/datadog-agent/conf.d/rabbitmq.d/:/etc/datadog-agent/conf.d/rabbitmq.d:ro \
        -e DD_API_KEY=$DD_API_KEY \
        -e IP=$IP \
        -e DD_RMQ_PASS=$DD_RMQ_PASS \
        ${dd_image}


runcmd:
  - yum update -y
  - yum install -y docker jq
  - wget https://s3.amazonaws.com/amazoncloudwatch-agent/amazon_linux/amd64/latest/amazon-cloudwatch-agent.rpm
  - sudo rpm -U ./amazon-cloudwatch-agent.rpm
  - sudo /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/bin/config.json -s
  - service docker start
  - chkconfig docker on
  - usermod -a -G docker ec2-user
  - service datadog-agent start
  - $(aws ecr get-login --no-include-email --region ${region} --registry-ids ${ecr_registry_id})
  - sleep 1
  - docker run -d --name rabbitmq --hostname $HOSTNAME --log-driver=awslogs --log-opt awslogs-region=${region} --log-opt awslogs-group=${cw_log_group} -p 4369:4369 -p 5672:5672 -p 15672:15672 -p 25672:25672 -e RABBITMQ_ERLANG_COOKIE='${secret_cookie}' -v /root/data:/var/lib/rabbitmq -v /root/conf/:/etc/rabbitmq -v /root/bin:/tmp/bin ${rabbitmq_image}
  - sleep 1
  - bash /root/find_hosts.sh
  - docker exec rabbitmq bash /tmp/bin/join_cluster.sh $(bash /root/find_hosts.sh)
  - sleep 1
  - bash /root/configure.sh
  - sleep 1
  - bash /root/configure_datadog_user.sh
